"""
–û–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –º–µ–Ω–µ–¥–∂–µ—Ä –ø–∞–º—è—Ç–∏ —Å –ø—Ä–µ–¥–æ—Ç–≤—Ä–∞—â–µ–Ω–∏–µ–º —É—Ç–µ—á–µ–∫
–†–µ–∞–ª–∏–∑—É–µ—Ç –∏–Ω—Ç–µ–ª–ª–µ–∫—Ç—É–∞–ª—å–Ω–æ–µ —É–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –ø–∞–º—è—Ç—å—é –¥–ª—è AI –∞–≥–µ–Ω—Ç–∞
"""

import logging
import gc
import psutil
import os
from typing import Dict, List, Any, Optional, Tuple
from datetime import datetime, timedelta
from collections import deque, OrderedDict
import threading
import time
from weakref import WeakValueDictionary

from ..core.models import MemoryEntry

logger = logging.getLogger("MemoryManagerOptimized")


class MemoryEntryMetadata:
    """–ú–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ –¥–ª—è –∑–∞–ø–∏—Å–∏ –ø–∞–º—è—Ç–∏"""

    def __init__(self, entry_id: str, size_bytes: int, importance: float = 0.5,
                 access_count: int = 0, last_access: datetime = None):
        self.entry_id = entry_id
        self.size_bytes = size_bytes
        self.importance = importance
        self.access_count = access_count
        self.last_access = last_access or datetime.now()
        self.created_at = datetime.now()

    def update_access(self):
        """–û–±–Ω–æ–≤–ª–µ–Ω–∏–µ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ –¥–æ—Å—Ç—É–ø–∞"""
        self.access_count += 1
        self.last_access = datetime.now()

    def get_age_days(self) -> float:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ –≤–æ–∑—Ä–∞—Å—Ç–∞ –∑–∞–ø–∏—Å–∏ –≤ –¥–Ω—è—Ö"""
        return (datetime.now() - self.created_at).total_seconds() / (24 * 3600)

    def get_inactivity_days(self) -> float:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ –¥–Ω–µ–π –±–µ–∑ –¥–æ—Å—Ç—É–ø–∞"""
        return (datetime.now() - self.last_access).total_seconds() / (24 * 3600)

    def calculate_relevance_score(self) -> float:
        """–†–∞—Å—á–µ—Ç —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç–∏ –∑–∞–ø–∏—Å–∏"""
        # –§–æ—Ä–º—É–ª–∞: importance * (1 / (1 + age)) * (1 / (1 + inactivity)) * access_bonus
        age_penalty = 1 / (1 + self.get_age_days())
        inactivity_penalty = 1 / (1 + self.get_inactivity_days())
        access_bonus = min(2.0, 1 + (self.access_count * 0.1))

        return self.importance * age_penalty * inactivity_penalty * access_bonus


class MemoryPool:
    """–ü—É–ª –ø–∞–º—è—Ç–∏ —Å –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–µ–º —Ä–∞–∑–º–µ—Ä–∞"""

    def __init__(self, max_size_mb: float = 100.0, cleanup_threshold: float = 0.8):
        self.max_size_bytes = int(max_size_mb * 1024 * 1024)
        self.cleanup_threshold = cleanup_threshold  # –ü—Ä–æ—Ü–µ–Ω—Ç –∑–∞–ø–æ–ª–Ω–µ–Ω–∏—è –¥–ª—è –∑–∞–ø—É—Å–∫–∞ –æ—á–∏—Å—Ç–∫–∏
        self.current_size_bytes = 0
        self.entries: OrderedDict[str, Any] = OrderedDict()
        self.metadata: Dict[str, MemoryEntryMetadata] = {}
        self.lock = threading.RLock()

    def add_entry(self, entry_id: str, data: Any, importance: float = 0.5) -> bool:
        """
        –î–æ–±–∞–≤–ª–µ–Ω–∏–µ –∑–∞–ø–∏—Å–∏ –≤ –ø—É–ª

        Args:
            entry_id: ID –∑–∞–ø–∏—Å–∏
            data: –î–∞–Ω–Ω—ã–µ –∑–∞–ø–∏—Å–∏
            importance: –í–∞–∂–Ω–æ—Å—Ç—å (0.0-1.0)

        Returns:
            True –µ—Å–ª–∏ –¥–æ–±–∞–≤–ª–µ–Ω–æ, False –µ—Å–ª–∏ –Ω–µ—Ç –º–µ—Å—Ç–∞
        """
        with self.lock:
            # –û—Ü–µ–Ω–∫–∞ —Ä–∞–∑–º–µ—Ä–∞ –¥–∞–Ω–Ω—ã—Ö
            size_bytes = self._estimate_size(data)

            # –ü—Ä–æ–≤–µ—Ä–∫–∞ –¥–æ—Å—Ç—É–ø–Ω–æ–≥–æ –º–µ—Å—Ç–∞
            if self.current_size_bytes + size_bytes > self.max_size_bytes:
                # –ü–æ–ø—ã—Ç–∫–∞ –æ—á–∏—Å—Ç–∫–∏
                if not self._cleanup_space(size_bytes):
                    return False

            # –î–æ–±–∞–≤–ª–µ–Ω–∏–µ –∑–∞–ø–∏—Å–∏
            self.entries[entry_id] = data
            self.metadata[entry_id] = MemoryEntryMetadata(
                entry_id=entry_id,
                size_bytes=size_bytes,
                importance=importance
            )
            self.current_size_bytes += size_bytes

            return True

    def get_entry(self, entry_id: str) -> Optional[Any]:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ –∑–∞–ø–∏—Å–∏"""
        with self.lock:
            if entry_id in self.entries:
                # –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ –¥–æ—Å—Ç—É–ø–∞
                if entry_id in self.metadata:
                    self.metadata[entry_id].update_access()
                return self.entries[entry_id]
            return None

    def remove_entry(self, entry_id: str) -> bool:
        """–£–¥–∞–ª–µ–Ω–∏–µ –∑–∞–ø–∏—Å–∏"""
        with self.lock:
            if entry_id in self.entries:
                size_bytes = self.metadata[entry_id].size_bytes
                del self.entries[entry_id]
                del self.metadata[entry_id]
                self.current_size_bytes -= size_bytes
                return True
            return False

    def get_stats(self) -> Dict[str, Any]:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ –ø—É–ª–∞"""
        with self.lock:
            return {
                "current_size_mb": self.current_size_bytes / (1024 * 1024),
                "max_size_mb": self.max_size_bytes / (1024 * 1024),
                "utilization_percent": (self.current_size_bytes / self.max_size_bytes) * 100,
                "entry_count": len(self.entries),
                "cleanup_threshold": self.cleanup_threshold * 100
            }

    def _estimate_size(self, data: Any) -> int:
        """–û—Ü–µ–Ω–∫–∞ —Ä–∞–∑–º–µ—Ä–∞ –¥–∞–Ω–Ω—ã—Ö –≤ –±–∞–π—Ç–∞—Ö"""
        try:
            # –ü—Ä–æ—Å—Ç–∞—è –æ—Ü–µ–Ω–∫–∞ - –º–æ–∂–Ω–æ —É–ª—É—á—à–∏—Ç—å –¥–ª—è –±–æ–ª–µ–µ —Ç–æ—á–Ω—ã—Ö —Ä–∞—Å—á–µ—Ç–æ–≤
            if isinstance(data, (str, bytes)):
                return len(data.encode('utf-8') if isinstance(data, str) else data)
            elif isinstance(data, dict):
                return sum(self._estimate_size(v) for v in data.values())
            elif isinstance(data, (list, tuple)):
                return sum(self._estimate_size(item) for item in data)
            else:
                # –î–ª—è –æ–±—ä–µ–∫—Ç–æ–≤ –∏—Å–ø–æ–ª—å–∑—É–µ–º –ø—Ä–∏–±–ª–∏–∑–∏—Ç–µ–ª—å–Ω—É—é –æ—Ü–µ–Ω–∫—É
                return 1024  # 1KB –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é
        except:
            return 1024  # Fallback

    def _cleanup_space(self, required_bytes: int) -> bool:
        """
        –û—á–∏—Å—Ç–∫–∞ –ø—Ä–æ—Å—Ç—Ä–∞–Ω—Å—Ç–≤–∞ –¥–ª—è –Ω–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö

        Returns:
            True –µ—Å–ª–∏ —É–¥–∞–ª–æ—Å—å –æ—Å–≤–æ–±–æ–¥–∏—Ç—å –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –º–µ—Å—Ç–∞
        """
        with self.lock:
            # –°–æ—Ä—Ç–∏—Ä–æ–≤–∫–∞ –∑–∞–ø–∏—Å–µ–π –ø–æ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç–∏ (–æ—Ç –º–µ–Ω–µ–µ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã—Ö –∫ –±–æ–ª–µ–µ)
            entries_by_relevance = sorted(
                self.metadata.items(),
                key=lambda x: x[1].calculate_relevance_score()
            )

            freed_bytes = 0
            removed_count = 0

            for entry_id, metadata in entries_by_relevance:
                if freed_bytes >= required_bytes:
                    break

                # –ù–µ —É–¥–∞–ª—è–µ–º –æ—á–µ–Ω—å –≤–∞–∂–Ω—ã–µ –∑–∞–ø–∏—Å–∏
                if metadata.importance >= 0.8:
                    continue

                # –£–¥–∞–ª–µ–Ω–∏–µ –∑–∞–ø–∏—Å–∏
                self.remove_entry(entry_id)
                freed_bytes += metadata.size_bytes
                removed_count += 1

            logger.info(f"Memory pool cleanup: freed {freed_bytes} bytes, removed {removed_count} entries")

            return freed_bytes >= required_bytes

    def cleanup_expired_entries(self, max_age_days: float = 30.0):
        """–û—á–∏—Å—Ç–∫–∞ —É—Å—Ç–∞—Ä–µ–≤—à–∏—Ö –∑–∞–ø–∏—Å–µ–π"""
        with self.lock:
            expired_ids = []
            for entry_id, metadata in self.metadata.items():
                if metadata.get_age_days() > max_age_days and metadata.importance < 0.7:
                    expired_ids.append(entry_id)

            for entry_id in expired_ids:
                self.remove_entry(entry_id)

            if expired_ids:
                logger.info(f"Cleaned up {len(expired_ids)} expired memory entries")


class OptimizedMemoryManager:
    """
    –û–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –º–µ–Ω–µ–¥–∂–µ—Ä –ø–∞–º—è—Ç–∏ —Å –ø—Ä–µ–¥–æ—Ç–≤—Ä–∞—â–µ–Ω–∏–µ–º —É—Ç–µ—á–µ–∫.

    –ö–ª—é—á–µ–≤—ã–µ —É–ª—É—á—à–µ–Ω–∏—è:
    - –ò–Ω—Ç–µ–ª–ª–µ–∫—Ç—É–∞–ª—å–Ω–æ–µ —É–ø—Ä–∞–≤–ª–µ–Ω–∏–µ —Ä–∞–∑–º–µ—Ä–æ–º –ø–∞–º—è—Ç–∏
    - –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∞—è –æ—á–∏—Å—Ç–∫–∞ —É—Å—Ç–∞—Ä–µ–≤—à–∏—Ö –¥–∞–Ω–Ω—ã—Ö
    - –ú–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –ø–∞–º—è—Ç–∏
    - –ó–∞—â–∏—Ç–∞ –æ—Ç —É—Ç–µ—á–µ–∫ –ø–∞–º—è—Ç–∏
    """

    def __init__(self,
                 max_episodic_entries: int = 1000,
                 max_working_memory_mb: float = 50.0,
                 max_semantic_memory_mb: float = 100.0,
                 cleanup_interval_seconds: int = 300):
        """
        –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ –º–µ–Ω–µ–¥–∂–µ—Ä–∞ –ø–∞–º—è—Ç–∏

        Args:
            max_episodic_entries: –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —ç–ø–∏–∑–æ–¥–∏—á–µ—Å–∫–∏—Ö –∑–∞–ø–∏—Å–µ–π
            max_working_memory_mb: –ú–∞–∫—Å–∏–º–∞–ª—å–Ω—ã–π —Ä–∞–∑–º–µ—Ä —Ä–∞–±–æ—á–µ–π –ø–∞–º—è—Ç–∏ (MB)
            max_semantic_memory_mb: –ú–∞–∫—Å–∏–º–∞–ª—å–Ω—ã–π —Ä–∞–∑–º–µ—Ä —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–æ–π –ø–∞–º—è—Ç–∏ (MB)
            cleanup_interval_seconds: –ò–Ω—Ç–µ—Ä–≤–∞–ª –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–π –æ—á–∏—Å—Ç–∫–∏ (—Å–µ–∫—É–Ω–¥—ã)
        """
        # –ü—É–ª—ã –ø–∞–º—è—Ç–∏ —Å –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏—è–º–∏
        self.episodic_pool = MemoryPool(max_size_mb=max_semantic_memory_mb)
        self.working_pool = MemoryPool(max_size_mb=max_working_memory_mb)
        self.semantic_pool = MemoryPool(max_size_mb=max_semantic_memory_mb)

        # –û–≥—Ä–∞–Ω–∏—á–µ–Ω–∏—è –¥–ª—è –æ–±—Ä–∞—Ç–Ω–æ–π —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏
        self.max_episodic_entries = max_episodic_entries

        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –∏ –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥
        self.memory_stats = {
            "total_operations": 0,
            "cleanup_operations": 0,
            "memory_warnings": 0,
            "last_cleanup": datetime.now(),
            "start_time": datetime.now()
        }

        # –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∞—è –æ—á–∏—Å—Ç–∫–∞
        self.cleanup_interval = cleanup_interval_seconds
        self._start_cleanup_thread()

        # Weak references –¥–ª—è –ø—Ä–µ–¥–æ—Ç–≤—Ä–∞—â–µ–Ω–∏—è —Ü–∏–∫–ª–∏—á–µ—Å–∫–∏—Ö —Å—Å—ã–ª–æ–∫
        self._weak_references = WeakValueDictionary()

        logger.info("üöÄ OptimizedMemoryManager initialized with memory limits")

    def __del__(self):
        """–û—á–∏—Å—Ç–∫–∞ –ø—Ä–∏ —É–Ω–∏—á—Ç–æ–∂–µ–Ω–∏–∏ –æ–±—ä–µ–∫—Ç–∞"""
        try:
            self._stop_cleanup_thread()
        except:
            pass

    # ===== –≠–ü–ò–ó–û–î–ò–ß–ï–°–ö–ê–Ø –ü–ê–ú–Ø–¢–¨ =====

    async def store_episodic_memory(self, memory_data: Dict[str, Any], importance: float = 0.5):
        """
        –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —ç–ø–∏–∑–æ–¥–∏—á–µ—Å–∫–æ–π –ø–∞–º—è—Ç–∏ —Å –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–µ–π

        Args:
            memory_data: –î–∞–Ω–Ω—ã–µ –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è
            importance: –í–∞–∂–Ω–æ—Å—Ç—å –∑–∞–ø–∏—Å–∏ (0.0-1.0)
        """
        try:
            self.memory_stats["total_operations"] += 1

            # –°–æ–∑–¥–∞–Ω–∏–µ ID –¥–ª—è –∑–∞–ø–∏—Å–∏
            entry_id = f"episodic_{int(time.time() * 1000000)}_{hash(str(memory_data)) % 10000}"

            # –ü–æ–ø—ã—Ç–∫–∞ –¥–æ–±–∞–≤–ª–µ–Ω–∏—è –≤ –ø—É–ª
            if self.episodic_pool.add_entry(entry_id, memory_data, importance):
                logger.debug(f"Stored episodic memory: {entry_id}")
            else:
                logger.warning(f"Failed to store episodic memory: insufficient space")

        except Exception as e:
            logger.error(f"‚ùå Failed to store episodic memory: {e}")

    def retrieve_episodic_memory(self, limit: int = 10, min_importance: float = 0.0) -> List[Any]:
        """
        –ü–æ–ª—É—á–µ–Ω–∏–µ —ç–ø–∏–∑–æ–¥–∏—á–µ—Å–∫–æ–π –ø–∞–º—è—Ç–∏ —Å —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–µ–π

        Args:
            limit: –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∑–∞–ø–∏—Å–µ–π
            min_importance: –ú–∏–Ω–∏–º–∞–ª—å–Ω–∞—è –≤–∞–∂–Ω–æ—Å—Ç—å

        Returns:
            –°–ø–∏—Å–æ–∫ –∑–∞–ø–∏—Å–µ–π –ø–∞–º—è—Ç–∏
        """
        # –ü–æ–ª—É—á–µ–Ω–∏–µ –∑–∞–ø–∏—Å–µ–π, –æ—Ç—Å–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –ø–æ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç–∏
        relevant_entries = []

        for entry_id, metadata in self.episodic_pool.metadata.items():
            if metadata.importance >= min_importance:
                data = self.episodic_pool.get_entry(entry_id)
                if data:
                    relevant_entries.append((data, metadata.calculate_relevance_score()))

        # –°–æ—Ä—Ç–∏—Ä–æ–≤–∫–∞ –ø–æ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç–∏ –∏ –≤–æ–∑–≤—Ä–∞—Ç —Ç–æ–ø-N
        relevant_entries.sort(key=lambda x: x[1], reverse=True)
        return [data for data, score in relevant_entries[:limit]]

    # ===== –†–ê–ë–û–ß–ê–Ø –ü–ê–ú–Ø–¢–¨ =====

    def store_working_memory(self, key: str, value: Any, ttl_seconds: Optional[int] = None, importance: float = 0.7):
        """
        –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –≤ —Ä–∞–±–æ—á–µ–π –ø–∞–º—è—Ç–∏ —Å TTL

        Args:
            key: –ö–ª—é—á
            value: –ó–Ω–∞—á–µ–Ω–∏–µ
            ttl_seconds: –í—Ä–µ–º—è –∂–∏–∑–Ω–∏ (None - –±–µ—Å—Å—Ä–æ—á–Ω–æ)
            importance: –í–∞–∂–Ω–æ—Å—Ç—å
        """
        try:
            self.memory_stats["total_operations"] += 1

            # –î–æ–±–∞–≤–ª–µ–Ω–∏–µ TTL –≤ –¥–∞–Ω–Ω—ã–µ
            enriched_value = {
                "data": value,
                "expires_at": (datetime.now() + timedelta(seconds=ttl_seconds)).isoformat() if ttl_seconds else None,
                "stored_at": datetime.now().isoformat()
            }

            if self.working_pool.add_entry(key, enriched_value, importance):
                logger.debug(f"Stored working memory: {key}")
            else:
                logger.warning(f"Failed to store working memory: {key} - insufficient space")

        except Exception as e:
            logger.error(f"‚ùå Failed to store working memory: {e}")

    def retrieve_working_memory(self, key: str) -> Optional[Any]:
        """
        –ü–æ–ª—É—á–µ–Ω–∏–µ –∏–∑ —Ä–∞–±–æ—á–µ–π –ø–∞–º—è—Ç–∏ —Å –ø—Ä–æ–≤–µ—Ä–∫–æ–π TTL

        Args:
            key: –ö–ª—é—á

        Returns:
            –ó–Ω–∞—á–µ–Ω–∏–µ –∏–ª–∏ None
        """
        try:
            enriched_value = self.working_pool.get_entry(key)
            if not enriched_value:
                return None

            # –ü—Ä–æ–≤–µ—Ä–∫–∞ TTL
            if enriched_value.get("expires_at"):
                expires_at = datetime.fromisoformat(enriched_value["expires_at"])
                if datetime.now() > expires_at:
                    # –£–¥–∞–ª–µ–Ω–∏–µ –∏—Å—Ç–µ–∫—à–µ–π –∑–∞–ø–∏—Å–∏
                    self.working_pool.remove_entry(key)
                    logger.debug(f"Working memory entry expired: {key}")
                    return None

            return enriched_value["data"]

        except Exception as e:
            logger.error(f"‚ùå Failed to retrieve working memory: {e}")
            return None

    # ===== –°–ï–ú–ê–ù–¢–ò–ß–ï–°–ö–ê–Ø –ü–ê–ú–Ø–¢–¨ =====

    def store_semantic_memory(self, key: str, value: Any, importance: float = 0.8):
        """
        –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–æ–π –ø–∞–º—è—Ç–∏

        Args:
            key: –ö–ª—é—á
            value: –ó–Ω–∞—á–µ–Ω–∏–µ
            importance: –í–∞–∂–Ω–æ—Å—Ç—å (–≤—ã—Å–æ–∫–∞—è –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é –¥–ª—è —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–æ–π –ø–∞–º—è—Ç–∏)
        """
        try:
            self.memory_stats["total_operations"] += 1

            if self.semantic_pool.add_entry(key, value, importance):
                logger.debug(f"Stored semantic memory: {key}")
            else:
                logger.warning(f"Failed to store semantic memory: {key} - insufficient space")

        except Exception as e:
            logger.error(f"‚ùå Failed to store semantic memory: {e}")

    def retrieve_semantic_memory(self, key: str) -> Optional[Any]:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–æ–π –ø–∞–º—è—Ç–∏"""
        return self.semantic_pool.get_entry(key)

    # ===== –ú–û–ù–ò–¢–û–†–ò–ù–ì –ò –û–ü–¢–ò–ú–ò–ó–ê–¶–ò–Ø =====

    def get_memory_stats(self) -> Dict[str, Any]:
        """
        –ü–æ–ª—É—á–µ–Ω–∏–µ –ø–æ–¥—Ä–æ–±–Ω–æ–π —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –ø–∞–º—è—Ç–∏

        Returns:
            –î–µ—Ç–∞–ª—å–Ω–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
        """
        # –°–±–æ—Ä —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ –æ—Ç –≤—Å–µ—Ö –ø—É–ª–æ–≤
        episodic_stats = self.episodic_pool.get_stats()
        working_stats = self.working_pool.get_stats()
        semantic_stats = self.semantic_pool.get_stats()

        # –°–∏—Å—Ç–µ–º–Ω–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
        process = psutil.Process(os.getpid())
        system_memory = process.memory_info()

        # –†–∞—Å—á–µ—Ç –æ–±—â–µ–π —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç–∏
        total_utilization = (
            episodic_stats["utilization_percent"] +
            working_stats["utilization_percent"] +
            semantic_stats["utilization_percent"]
        ) / 3

        return {
            "pools": {
                "episodic": episodic_stats,
                "working": working_stats,
                "semantic": semantic_stats
            },
            "system": {
                "rss_mb": system_memory.rss / (1024 * 1024),
                "vms_mb": system_memory.vms / (1024 * 1024),
                "cpu_percent": process.cpu_percent(interval=0.1)
            },
            "operations": {
                "total": self.memory_stats["total_operations"],
                "cleanup_count": self.memory_stats["cleanup_operations"],
                "warnings": self.memory_stats["memory_warnings"]
            },
            "performance": {
                "average_utilization_percent": total_utilization,
                "uptime_hours": (datetime.now() - self.memory_stats["start_time"]).total_seconds() / 3600,
                "last_cleanup": self.memory_stats["last_cleanup"].isoformat()
            }
        }

    def optimize_memory(self) -> Dict[str, Any]:
        """
        –û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –ø–∞–º—è—Ç–∏

        Returns:
            –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏
        """
        logger.info("üîÑ Starting memory optimization")

        results = {
            "freed_bytes": 0,
            "removed_entries": 0,
            "pools_optimized": 0,
            "gc_collections": 0
        }

        # –û—á–∏—Å—Ç–∫–∞ —É—Å—Ç–∞—Ä–µ–≤—à–∏—Ö –∑–∞–ø–∏—Å–µ–π
        self.episodic_pool.cleanup_expired_entries(max_age_days=7.0)  # –ù–µ–¥–µ–ª—è
        self.working_pool.cleanup_expired_entries(max_age_days=1.0)   # –î–µ–Ω—å
        self.semantic_pool.cleanup_expired_entries(max_age_days=30.0) # –ú–µ—Å—è—Ü

        # –ü—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω—ã–π —Å–±–æ—Ä –º—É—Å–æ—Ä–∞
        collected = gc.collect()
        results["gc_collections"] = collected

        # –†–∞—Å—á–µ—Ç –æ—Å–≤–æ–±–æ–∂–¥–µ–Ω–Ω–æ–≥–æ –º–µ—Å—Ç–∞ (–ø—Ä–∏–±–ª–∏–∑–∏—Ç–µ–ª—å–Ω–æ)
        # –í —Ä–µ–∞–ª—å–Ω–æ—Å—Ç–∏ –Ω—É–∂–Ω–æ –æ—Ç—Å–ª–µ–∂–∏–≤–∞—Ç—å –¥–æ/–ø–æ—Å–ª–µ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏

        self.memory_stats["cleanup_operations"] += 1
        self.memory_stats["last_cleanup"] = datetime.now()

        logger.info(f"‚úÖ Memory optimization completed: {results}")
        return results

    def check_memory_health(self) -> Dict[str, Any]:
        """
        –ü—Ä–æ–≤–µ—Ä–∫–∞ –∑–¥–æ—Ä–æ–≤—å—è –ø–∞–º—è—Ç–∏

        Returns:
            –°—Ç–∞—Ç—É—Å –∑–¥–æ—Ä–æ–≤—å—è
        """
        stats = self.get_memory_stats()

        health_status = "healthy"
        issues = []

        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –ø–µ—Ä–µ–ø–æ–ª–Ω–µ–Ω–∏—è –ø—É–ª–æ–≤
        for pool_name, pool_stats in stats["pools"].items():
            if pool_stats["utilization_percent"] > 90:
                health_status = "critical"
                issues.append(f"{pool_name} pool over 90% full")
            elif pool_stats["utilization_percent"] > 75:
                if health_status == "healthy":
                    health_status = "warning"
                issues.append(f"{pool_name} pool over 75% full")

        # –ü—Ä–æ–≤–µ—Ä–∫–∞ —Å–∏—Å—Ç–µ–º–Ω–æ–π –ø–∞–º—è—Ç–∏
        if stats["system"]["rss_mb"] > 500:  # 500MB
            health_status = "critical"
            issues.append("High system memory usage")

        return {
            "status": health_status,
            "issues": issues,
            "recommendations": self._get_memory_recommendations(health_status, issues)
        }

    def _get_memory_recommendations(self, status: str, issues: List[str]) -> List[str]:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π –ø–æ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ –ø–∞–º—è—Ç–∏"""
        recommendations = []

        if status == "critical":
            recommendations.extend([
                "Immediate memory cleanup required",
                "Consider increasing memory limits",
                "Review memory-intensive operations"
            ])

        if status == "warning":
            recommendations.extend([
                "Schedule memory optimization",
                "Monitor memory usage trends",
                "Consider reducing cache sizes"
            ])

        for issue in issues:
            if "episodic" in issue:
                recommendations.append("Clean up old episodic memory entries")
            elif "working" in issue:
                recommendations.append("Clear expired working memory entries")
            elif "semantic" in issue:
                recommendations.append("Archive unused semantic memory")

        return recommendations

    # ===== –ê–í–¢–û–ú–ê–¢–ò–ß–ï–°–ö–ê–Ø –û–ß–ò–°–¢–ö–ê =====

    def _start_cleanup_thread(self):
        """–ó–∞–ø—É—Å–∫ –ø–æ—Ç–æ–∫–∞ –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–π –æ—á–∏—Å—Ç–∫–∏"""
        self._cleanup_thread = threading.Thread(
            target=self._cleanup_worker,
            daemon=True,
            name="MemoryCleanup"
        )
        self._cleanup_thread.start()

    def _stop_cleanup_thread(self):
        """–û—Å—Ç–∞–Ω–æ–≤–∫–∞ –ø–æ—Ç–æ–∫–∞ –æ—á–∏—Å—Ç–∫–∏"""
        if hasattr(self, '_cleanup_thread'):
            self._cleanup_thread = None

    def _cleanup_worker(self):
        """–†–∞–±–æ—á–∏–π –ø–æ—Ç–æ–∫ –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–π –æ—á–∏—Å—Ç–∫–∏"""
        while True:
            try:
                time.sleep(self.cleanup_interval)

                # –ü—Ä–æ–≤–µ—Ä–∫–∞ –∑–¥–æ—Ä–æ–≤—å—è –∏ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –µ—Å–ª–∏ –Ω—É–∂–Ω–æ
                health = self.check_memory_health()
                if health["status"] in ["warning", "critical"]:
                    logger.info("Running scheduled memory optimization")
                    self.optimize_memory()
                    self.memory_stats["cleanup_operations"] += 1

            except Exception as e:
                logger.error(f"Error in memory cleanup worker: {e}")
                time.sleep(60)  # –ü–∞—É–∑–∞ –ø—Ä–∏ –æ—à–∏–±–∫–µ

    # ===== –°–û–í–ú–ï–°–¢–ò–ú–û–°–¢–¨ =====

    def clear_memory(self, memory_type: str = "all"):
        """–û—á–∏—Å—Ç–∫–∞ –ø–∞–º—è—Ç–∏ (–¥–ª—è —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏)"""
        if memory_type in ["episodic", "all"]:
            # –û—á–∏—Å—Ç–∫–∞ episodic –ø—É–ª–∞
            entry_ids = list(self.episodic_pool.entries.keys())
            for entry_id in entry_ids:
                self.episodic_pool.remove_entry(entry_id)

        if memory_type in ["working", "all"]:
            # –û—á–∏—Å—Ç–∫–∞ working –ø—É–ª–∞
            entry_ids = list(self.working_pool.entries.keys())
            for entry_id in entry_ids:
                self.working_pool.remove_entry(entry_id)

        if memory_type in ["semantic", "all"]:
            # –û—á–∏—Å—Ç–∫–∞ semantic –ø—É–ª–∞
            entry_ids = list(self.semantic_pool.entries.keys())
            for entry_id in entry_ids:
                self.semantic_pool.remove_entry(entry_id)

        logger.info(f"Memory cleared: {memory_type}")

    # ===== –£–¢–ò–õ–ò–¢–´ =====

    def __str__(self) -> str:
        """–°—Ç—Ä–æ–∫–æ–≤–æ–µ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∏–µ"""
        stats = self.get_memory_stats()
        return (f"OptimizedMemoryManager("
                f"episodic: {stats['pools']['episodic']['utilization_percent']:.1f}%, "
                f"working: {stats['pools']['working']['utilization_percent']:.1f}%, "
                f"semantic: {stats['pools']['semantic']['utilization_percent']:.1f}%, "
                f"system: {stats['system']['rss_mb']:.1f}MB)")
