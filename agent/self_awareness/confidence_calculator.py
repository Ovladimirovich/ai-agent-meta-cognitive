import logging
import numpy as np
from typing import Dict, Any, Optional, List, Tuple
from datetime import datetime, timedelta
from collections import defaultdict

from ..core.models import QueryAnalysis

logger = logging.getLogger("ConfidenceCalculator")


class ConfidenceCalculator:
    """
    –ö–∞–ª—å–∫—É–ª—è—Ç–æ—Ä —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏ –∞–≥–µ–Ω—Ç–∞.

    –û—Ü–µ–Ω–∏–≤–∞–µ—Ç —É—Ä–æ–≤–µ–Ω—å —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏ –≤ –æ—Ç–≤–µ—Ç–µ –Ω–∞ –æ—Å–Ω–æ–≤–µ —Ä–∞–∑–ª–∏—á–Ω—ã—Ö —Ñ–∞–∫—Ç–æ—Ä–æ–≤:
    - –ö–∞—á–µ—Å—Ç–≤–∞ –æ—Ç–≤–µ—Ç–∞ –º–æ–¥–µ–ª–∏
    - –£—Å–ø–µ—à–Ω–æ—Å—Ç–∏ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–æ–≤
    - –†–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç–∏ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞
    - –ò—Å—Ç–æ—Ä–∏—á–µ—Å–∫–æ–π –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏
    """

    def __init__(self):
        self.historical_performance: Dict[str, float] = {}
        self.intent_performance: Dict[str, Dict[str, float]] = {}

        # –ú–∞—à–∏–Ω–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ –¥–ª—è –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏
        self.ml_model = None
        self.training_data: List[Tuple[List[float], float]] = []
        self.feature_weights = {
            'model_confidence': 0.4,
            'tool_success_rate': 0.3,
            'context_relevance': 0.2,
            'historical_performance': 0.1,
            'response_length': 0.05,
            'tool_count': -0.05,
            'complexity_penalty': -0.1,
            'time_factor': 0.02
        }

        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –¥–ª—è –æ–±—É—á–µ–Ω–∏—è
        self.prediction_history: List[Tuple[List[float], float, float]] = []  # features, predicted, actual
        self.accuracy_stats = {
            'total_predictions': 0,
            'accurate_predictions': 0,
            'mean_error': 0.0,
            'last_calibration': None
        }

        logger.info("üöÄ ConfidenceCalculator with ML initialized")

    def calculate(self, result: Any, analysis: QueryAnalysis) -> float:
        """
        –†–∞—Å—á–µ—Ç —É—Ä–æ–≤–Ω—è —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏ –≤ –æ—Ç–≤–µ—Ç–µ.

        Args:
            result: –†–µ–∑—É–ª—å—Ç–∞—Ç –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è –∑–∞–ø—Ä–æ—Å–∞
            analysis: –ê–Ω–∞–ª–∏–∑ –∑–∞–ø—Ä–æ—Å–∞

        Returns:
            –£—Ä–æ–≤–µ–Ω—å —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏ –æ—Ç 0.0 –¥–æ 1.0
        """
        try:
            confidence_factors = {
                'model_confidence': self._get_model_confidence(result),
                'tool_success_rate': self._calculate_tool_success_rate(analysis.required_tools),
                'context_relevance': self._assess_context_relevance(result, analysis),
                'historical_performance': self._get_historical_performance(analysis.intent)
            }

            # –í–∑–≤–µ—à–µ–Ω–Ω–æ–µ —Å—Ä–µ–¥–Ω–µ–µ —Å –∫–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç–∞–º–∏
            weights = {
                'model_confidence': 0.4,
                'tool_success_rate': 0.3,
                'context_relevance': 0.2,
                'historical_performance': 0.1
            }

            confidence = sum(
                confidence_factors[factor] * weights[factor]
                for factor in confidence_factors
            )

            # –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è –≤ –¥–∏–∞–ø–∞–∑–æ–Ω [0, 1]
            confidence = max(0.0, min(1.0, confidence))

            logger.debug(f"Calculated confidence: {confidence:.3f} for intent '{analysis.intent}'")
            return confidence

        except Exception as e:
            logger.error(f"‚ùå Confidence calculation failed: {e}")
            return 0.1  # –ú–∏–Ω–∏–º–∞–ª—å–Ω–∞—è —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å –ø—Ä–∏ –æ—à–∏–±–∫–µ

    def _get_model_confidence(self, result: Any) -> float:
        """
        –û—Ü–µ–Ω–∫–∞ —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏ –Ω–∞ –æ—Å–Ω–æ–≤–µ –∫–∞—á–µ—Å—Ç–≤–∞ –æ—Ç–≤–µ—Ç–∞ –º–æ–¥–µ–ª–∏.

        –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç:
        - –î–ª–∏–Ω—É –æ—Ç–≤–µ—Ç–∞ (—Å–ª–∏—à–∫–æ–º –∫–æ—Ä–æ—Ç–∫–∏–µ –º–æ–≥—É—Ç –±—ã—Ç—å –Ω–µ—É–≤–µ—Ä–µ–Ω–Ω—ã–º–∏)
        - –ù–∞–ª–∏—á–∏–µ –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
        - –û—Ç—Å—É—Ç—Å—Ç–≤–∏–µ —Ñ—Ä–∞–∑ –Ω–µ—É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏
        """
        if not result or not isinstance(result, str):
            return 0.3  # –ù–∏–∑–∫–∞—è —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å –¥–ª—è –ø—É—Å—Ç—ã—Ö –∏–ª–∏ –Ω–µ—Å—Ç—Ä–æ–∫–æ–≤—ã—Ö —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤

        result_str = str(result).strip()

        # –ë–∞–∑–æ–≤–∞—è –æ—Ü–µ–Ω–∫–∞ –ø–æ –¥–ª–∏–Ω–µ
        length_score = min(1.0, len(result_str) / 100.0)  # –ú–∞–∫—Å–∏–º—É–º –∑–∞ 100 —Å–∏–º–≤–æ–ª–æ–≤

        # –®—Ç—Ä–∞—Ñ –∑–∞ —Ñ—Ä–∞–∑—ã –Ω–µ—É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏
        uncertainty_phrases = [
            "—è –Ω–µ –∑–Ω–∞—é", "–Ω–µ —É–≤–µ—Ä–µ–Ω", "–≤–æ–∑–º–æ–∂–Ω–æ", "–º–æ–∂–µ—Ç –±—ã—Ç—å",
            "–∫–∞–∂–µ—Ç—Å—è", "–ø–æ—Ö–æ–∂–µ", "–Ω–∞–≤–µ—Ä–Ω–æ–µ", "–≤–µ—Ä–æ—è—Ç–Ω–æ"
        ]

        uncertainty_penalty = 0.0
        for phrase in uncertainty_phrases:
            if phrase.lower() in result_str.lower():
                uncertainty_penalty += 0.1

        uncertainty_penalty = min(0.5, uncertainty_penalty)  # –ú–∞–∫—Å–∏–º–∞–ª—å–Ω—ã–π —à—Ç—Ä–∞—Ñ 0.5

        # –ë–æ–Ω—É—Å –∑–∞ –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ
        specificity_bonus = 0.0
        if any(char.isdigit() for char in result_str):
            specificity_bonus += 0.1  # –¶–∏—Ñ—Ä—ã
        if len(result_str.split()) > 10:
            specificity_bonus += 0.1  # –î–ª–∏–Ω–Ω—ã–π –æ—Ç–≤–µ—Ç
        if "http" in result_str or "www" in result_str:
            specificity_bonus += 0.1  # –°—Å—ã–ª–∫–∏

        confidence = length_score - uncertainty_penalty + specificity_bonus
        return max(0.0, min(1.0, confidence))

    def _calculate_tool_success_rate(self, required_tools: list[str]) -> float:
        """
        –†–∞—Å—á–µ—Ç —É—Å–ø–µ—à–Ω–æ—Å—Ç–∏ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–æ–≤.

        –î–ª—è –ø–µ—Ä–≤–æ–π —Ñ–∞–∑—ã - –ø—Ä–æ—Å—Ç–∞—è –æ—Ü–µ–Ω–∫–∞ –Ω–∞ –æ—Å–Ω–æ–≤–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–æ–≤.
        –í –±—É–¥—É—â–µ–º –±—É–¥–µ—Ç –∏–Ω—Ç–µ–≥—Ä–∏—Ä–æ–≤–∞–Ω–∞ —Å —Ä–µ–∞–ª—å–Ω–æ–π —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–æ–π –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è.
        """
        if not required_tools:
            return 0.8  # –í—ã—Å–æ–∫–∞—è —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å –¥–ª—è –∑–∞–ø—Ä–æ—Å–æ–≤ –±–µ–∑ –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–æ–≤

        # –ë–∞–∑–æ–≤–∞—è –æ—Ü–µ–Ω–∫–∞: –º–µ–Ω—å—à–µ –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–æ–≤ = –≤—ã—à–µ —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å
        tool_count_penalty = min(0.3, len(required_tools) * 0.1)

        # –ü—Ä–µ–¥–ø–æ–ª–∞–≥–∞–µ–º–∞—è —É—Å–ø–µ—à–Ω–æ—Å—Ç—å –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–æ–≤ (–≤ –±—É–¥—É—â–µ–º - —Ä–µ–∞–ª—å–Ω–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞)
        assumed_success_rate = 0.85

        confidence = assumed_success_rate - tool_count_penalty
        return max(0.0, min(1.0, confidence))

    def _assess_context_relevance(self, result: Any, analysis: QueryAnalysis) -> float:
        """
        –û—Ü–µ–Ω–∫–∞ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç–∏ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞.

        –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞ –∏—Å—Ö–æ–¥–Ω–æ–º—É –∑–∞–ø—Ä–æ—Å—É –∏ –∫–æ–Ω—Ç–µ–∫—Å—Ç—É.
        """
        if not result or not analysis:
            return 0.5

        result_str = str(result).lower()
        query_str = analysis.context.get("original_query", "").lower() if analysis.context else ""

        if not query_str:
            return 0.7  # –°—Ä–µ–¥–Ω—è—è —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å –±–µ–∑ –∏—Å—Ö–æ–¥–Ω–æ–≥–æ –∑–∞–ø—Ä–æ—Å–∞

        # –ü—Ä–æ—Å—Ç–∞—è –æ—Ü–µ–Ω–∫–∞ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç–∏ –ø–æ —Å–æ–≤–ø–∞–¥–µ–Ω–∏—é –∫–ª—é—á–µ–≤—ã—Ö —Å–ª–æ–≤
        query_words = set(query_str.split())
        result_words = set(result_str.split())

        # –ö–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç –ñ–∞–∫–∫–∞—Ä–∞ –¥–ª—è –æ—Ü–µ–Ω–∫–∏ –ø–µ—Ä–µ—Å–µ—á–µ–Ω–∏—è
        intersection = query_words.intersection(result_words)
        union = query_words.union(result_words)

        if not union:
            return 0.5

        jaccard_similarity = len(intersection) / len(union)

        # –ü—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ –≤ –æ—Ü–µ–Ω–∫—É —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏
        relevance_score = min(1.0, jaccard_similarity * 2.0)  # –£–º–Ω–æ–∂–∞–µ–º –¥–ª—è –ª—É—á—à–µ–≥–æ –¥–∏–∞–ø–∞–∑–æ–Ω–∞

        return relevance_score

    def _get_historical_performance(self, intent: str) -> float:
        """
        –ü–æ–ª—É—á–µ–Ω–∏–µ –∏—Å—Ç–æ—Ä–∏—á–µ—Å–∫–æ–π –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ –¥–ª—è –¥–∞–Ω–Ω–æ–≥–æ –Ω–∞–º–µ—Ä–µ–Ω–∏—è.

        –í –ø–µ—Ä–≤–æ–π —Ñ–∞–∑–µ - –ø—Ä–æ—Å—Ç–∞—è –æ—Ü–µ–Ω–∫–∞ –Ω–∞ –æ—Å–Ω–æ–≤–µ —Ç–∏–ø–∞ –Ω–∞–º–µ—Ä–µ–Ω–∏—è.
        """
        # –ë–∞–∑–æ–≤—ã–µ –æ—Ü–µ–Ω–∫–∏ –ø–æ —Ç–∏–ø–∞–º –Ω–∞–º–µ—Ä–µ–Ω–∏–π
        intent_base_scores = {
            "greeting": 0.95,  # –ü—Ä–∏–≤–µ—Ç—Å—Ç–≤–∏—è –æ–±—ã—á–Ω–æ —É—Å–ø–µ—à–Ω—ã
            "question": 0.80,  # –í–æ–ø—Ä–æ—Å—ã –∑–∞–≤–∏—Å—è—Ç –æ—Ç —Å–ª–æ–∂–Ω–æ—Å—Ç–∏
            "search": 0.75,    # –ü–æ–∏—Å–∫ –º–æ–∂–µ—Ç –±—ã—Ç—å –Ω–µ—Ç–æ—á–Ω—ã–º
            "analyze": 0.70,   # –ê–Ω–∞–ª–∏–∑ –∑–∞–≤–∏—Å–∏—Ç –æ—Ç –¥–∞–Ω–Ω—ã—Ö
            "create": 0.65,    # –°–æ–∑–¥–∞–Ω–∏–µ —Ç—Ä–µ–±—É–µ—Ç –∫—Ä–µ–∞—Ç–∏–≤–Ω–æ—Å—Ç–∏
            "help": 0.85       # –ü–æ–º–æ—â—å –æ–±—ã—á–Ω–æ —É—Å–ø–µ—à–Ω–∞
        }

        base_score = intent_base_scores.get(intent, 0.7)  # –ó–Ω–∞—á–µ–Ω–∏–µ –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é

        # –í –±—É–¥—É—â–µ–º –∑–¥–µ—Å—å –±—É–¥–µ—Ç —Ä–µ–∞–ª—å–Ω–∞—è –∏—Å—Ç–æ—Ä–∏—á–µ—Å–∫–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
        # –ü–æ–∫–∞ –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –±–∞–∑–æ–≤—É—é –æ—Ü–µ–Ω–∫—É
        return base_score

    def update_historical_performance(self, intent: str, actual_confidence: float, success: bool):
        """
        –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ –∏—Å—Ç–æ—Ä–∏—á–µ—Å–∫–æ–π –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏.

        Args:
            intent: –¢–∏–ø –Ω–∞–º–µ—Ä–µ–Ω–∏—è
            actual_confidence: –§–∞–∫—Ç–∏—á–µ—Å–∫–∞—è —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å
            success: –£—Å–ø–µ—à–Ω–æ—Å—Ç—å –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è
        """
        if intent not in self.intent_performance:
            self.intent_performance[intent] = {
                "total_requests": 0,
                "successful_requests": 0,
                "average_confidence": 0.0,
                "total_confidence": 0.0
            }

        perf = self.intent_performance[intent]
        perf["total_requests"] += 1

        if success:
            perf["successful_requests"] += 1

        perf["total_confidence"] += actual_confidence
        perf["average_confidence"] = perf["total_confidence"] / perf["total_requests"]

        # –û–±–Ω–æ–≤–ª—è–µ–º –æ–±—â—É—é –∏—Å—Ç–æ—Ä–∏—á–µ—Å–∫—É—é –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å
        self.historical_performance[intent] = perf["average_confidence"]

        logger.debug(f"Updated performance for intent '{intent}': {perf['average_confidence']:.3f}")

    def get_performance_stats(self) -> Dict[str, Any]:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏"""
        return {
            "intent_performance": self.intent_performance.copy(),
            "overall_performance": self.historical_performance.copy()
        }

    def reset_performance_data(self):
        """–°–±—Ä–æ—Å –¥–∞–Ω–Ω—ã—Ö –æ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏"""
        self.historical_performance.clear()
        self.intent_performance.clear()
        logger.info("üîÑ Confidence calculator performance data reset")

    def calculate_with_ml(self, result: Any, analysis: QueryAnalysis) -> float:
        """
        –†–∞—Å—á–µ—Ç —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏ —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º –º–∞—à–∏–Ω–Ω–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è.

        –ò—Å–ø–æ–ª—å–∑—É–µ—Ç –æ–±—É—á–µ–Ω–Ω—É—é –º–æ–¥–µ–ª—å –¥–ª—è –±–æ–ª–µ–µ —Ç–æ—á–Ω–æ–≥–æ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è.
        """
        try:
            # –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
            features = self._extract_features(result, analysis)

            if self.ml_model and len(self.training_data) > 10:
                # –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ –æ–±—É—á–µ–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏
                confidence = self._predict_with_model(features)
            else:
                # Fallback –Ω–∞ rule-based —Ä–∞—Å—á–µ—Ç
                confidence = self.calculate(result, analysis)

            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ –¥–ª—è –ø–æ—Å–ª–µ–¥—É—é—â–µ–≥–æ –æ–±—É—á–µ–Ω–∏—è
            self.prediction_history.append((features, confidence, None))  # actual –±—É–¥–µ—Ç —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω –ø–æ–∑–∂–µ

            return confidence

        except Exception as e:
            logger.error(f"ML confidence calculation failed: {e}")
            return self.calculate(result, analysis)  # Fallback

    def _extract_features(self, result: Any, analysis: QueryAnalysis) -> List[float]:
        """–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –¥–ª—è ML –º–æ–¥–µ–ª–∏"""
        features = []

        # –ë–∞–∑–æ–≤—ã–µ —Ñ–∞–∫—Ç–æ—Ä—ã —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏
        model_conf = self._get_model_confidence(result)
        tool_success = self._calculate_tool_success_rate(analysis.required_tools or [])
        context_rel = self._assess_context_relevance(result, analysis)
        hist_perf = self._get_historical_performance(analysis.intent)

        features.extend([model_conf, tool_success, context_rel, hist_perf])

        # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏
        result_str = str(result) if result else ""

        # –î–ª–∏–Ω–∞ –æ—Ç–≤–µ—Ç–∞ (–Ω–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω–∞—è)
        response_length = min(1.0, len(result_str) / 500.0)
        features.append(response_length)

        # –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–æ–≤ (–Ω–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω–æ–µ)
        tool_count = len(analysis.required_tools or []) / 10.0
        features.append(tool_count)

        # –°–ª–æ–∂–Ω–æ—Å—Ç—å –∑–∞–ø—Ä–æ—Å–∞
        complexity = 0.0
        if analysis.complexity == "high":
            complexity = 1.0
        elif analysis.complexity == "medium":
            complexity = 0.5
        features.append(complexity)

        # –í—Ä–µ–º–µ–Ω–Ω–æ–π —Ñ–∞–∫—Ç–æ—Ä (–≤—Ä–µ–º—è —Å—É—Ç–æ–∫ –º–æ–∂–µ—Ç –≤–ª–∏—è—Ç—å –Ω–∞ —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å)
        current_hour = datetime.now().hour / 24.0
        features.append(current_hour)

        # –ü—Ä–∏–∑–Ω–∞–∫–∏ –∫–∞—á–µ—Å—Ç–≤–∞ –æ—Ç–≤–µ—Ç–∞
        has_numbers = 1.0 if any(char.isdigit() for char in result_str) else 0.0
        has_links = 1.0 if "http" in result_str or "www" in result_str else 0.0
        has_uncertainty = 1.0 if any(phrase in result_str.lower() for phrase in [
            "—è –Ω–µ –∑–Ω–∞—é", "–Ω–µ —É–≤–µ—Ä–µ–Ω", "–≤–æ–∑–º–æ–∂–Ω–æ", "–º–æ–∂–µ—Ç –±—ã—Ç—å"
        ]) else 0.0

        features.extend([has_numbers, has_links, has_uncertainty])

        return features

    def _predict_with_model(self, features: List[float]) -> float:
        """–ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏ —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º –æ–±—É—á–µ–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏"""
        if not self.ml_model:
            return sum(features) / len(features)  # –ü—Ä–æ—Å—Ç–æ–µ —Å—Ä–µ–¥–Ω–µ–µ

        # –î–ª—è –ø—Ä–æ—Å—Ç–æ–π –ª–∏–Ω–µ–π–Ω–æ–π –º–æ–¥–µ–ª–∏
        prediction = sum(w * f for w, f in zip(self.ml_model, features))
        return max(0.0, min(1.0, prediction))

    def train_ml_model(self, learning_rate: float = 0.01, epochs: int = 100):
        """
        –û–±—É—á–µ–Ω–∏–µ ML –º–æ–¥–µ–ª–∏ –Ω–∞ –∏—Å—Ç–æ—Ä–∏—á–µ—Å–∫–∏—Ö –¥–∞–Ω–Ω—ã—Ö.

        –ò—Å–ø–æ–ª—å–∑—É–µ—Ç –ø—Ä–æ—Å—Ç—É—é –ª–∏–Ω–µ–π–Ω—É—é —Ä–µ–≥—Ä–µ—Å—Å–∏—é —Å –≥—Ä–∞–¥–∏–µ–Ω—Ç–Ω—ã–º —Å–ø—É—Å–∫–æ–º.
        """
        if len(self.training_data) < 5:
            logger.warning("–ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –æ–±—É—á–µ–Ω–∏—è ML –º–æ–¥–µ–ª–∏")
            return

        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –≤–µ—Å–æ–≤
        n_features = len(self.training_data[0][0])
        if not self.ml_model:
            self.ml_model = [0.1] * n_features  # –ù–∞—á–∞–ª—å–Ω—ã–µ –≤–µ—Å–∞

        # –ì—Ä–∞–¥–∏–µ–Ω—Ç–Ω—ã–π —Å–ø—É—Å–∫
        for epoch in range(epochs):
            total_error = 0.0

            for features, actual_confidence in self.training_data:
                predicted = self._predict_with_model(features)
                error = predicted - actual_confidence
                total_error += error ** 2

                # –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ –≤–µ—Å–æ–≤
                for i in range(n_features):
                    self.ml_model[i] -= learning_rate * error * features[i]

            # –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è –≤–µ—Å–æ–≤
            total_weight = sum(abs(w) for w in self.ml_model)
            if total_weight > 0:
                self.ml_model = [w / total_weight for w in self.ml_model]

            if epoch % 20 == 0:
                mse = total_error / len(self.training_data)
                logger.debug(f"Epoch {epoch}: MSE = {mse:.4f}")

        self.accuracy_stats['last_calibration'] = datetime.now()
        logger.info("‚úÖ ML –º–æ–¥–µ–ª—å –æ–±—É—á–µ–Ω–∞")

    def add_training_example(self, result: Any, analysis: QueryAnalysis, actual_confidence: float):
        """
        –î–æ–±–∞–≤–ª–µ–Ω–∏–µ –ø—Ä–∏–º–µ—Ä–∞ –¥–ª—è –æ–±—É—á–µ–Ω–∏—è –º–æ–¥–µ–ª–∏.

        Args:
            result: –†–µ–∑—É–ª—å—Ç–∞—Ç –∑–∞–ø—Ä–æ—Å–∞
            analysis: –ê–Ω–∞–ª–∏–∑ –∑–∞–ø—Ä–æ—Å–∞
            actual_confidence: –§–∞–∫—Ç–∏—á–µ—Å–∫–∞—è —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å (–æ—Ü–µ–Ω–µ–Ω–Ω–∞—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–º –∏–ª–∏ —Å–∏—Å—Ç–µ–º–æ–π)
        """
        features = self._extract_features(result, analysis)
        self.training_data.append((features, actual_confidence))

        # –û–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–µ —Ä–∞–∑–º–µ—Ä–∞ –æ–±—É—á–∞—é—â–∏—Ö –¥–∞–Ω–Ω—ã—Ö
        if len(self.training_data) > 1000:
            self.training_data = self.training_data[-500:]  # –û—Å—Ç–∞–≤–ª—è–µ–º –ø–æ—Å–ª–µ–¥–Ω–∏–µ 500 –ø—Ä–∏–º–µ—Ä–æ–≤

    def calibrate_with_feedback(self, predicted_confidence: float, actual_confidence: float):
        """
        –ö–∞–ª–∏–±—Ä–æ–≤–∫–∞ –º–æ–¥–µ–ª–∏ –Ω–∞ –æ—Å–Ω–æ–≤–µ –æ–±—Ä–∞—Ç–Ω–æ–π —Å–≤—è–∑–∏.

        Args:
            predicted_confidence: –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–Ω–∞—è —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å
            actual_confidence: –§–∞–∫—Ç–∏—á–µ—Å–∫–∞—è —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å (–∏–∑ –æ–±—Ä–∞—Ç–Ω–æ–π —Å–≤—è–∑–∏)
        """
        # –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ —Ç–æ—á–Ω–æ—Å—Ç–∏
        self.accuracy_stats['total_predictions'] += 1

        error = abs(predicted_confidence - actual_confidence)
        if error < 0.2:  # –ü–æ—Ä–æ–≥ —Ç–æ—á–Ω–æ—Å—Ç–∏
            self.accuracy_stats['accurate_predictions'] += 1

        # –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ —Å—Ä–µ–¥–Ω–µ–π –æ—à–∏–±–∫–∏
        current_mean = self.accuracy_stats['mean_error']
        total = self.accuracy_stats['total_predictions']
        self.accuracy_stats['mean_error'] = (current_mean * (total - 1) + error) / total

        # –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–µ –ø–µ—Ä–µ–æ–±—É—á–µ–Ω–∏–µ –ø—Ä–∏ –Ω–∏–∑–∫–æ–π —Ç–æ—á–Ω–æ—Å—Ç–∏
        accuracy_rate = self.accuracy_stats['accurate_predictions'] / total
        if accuracy_rate < 0.7 and total % 50 == 0:  # –ö–∞–∂–¥—ã–µ 50 –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π
            logger.info("üîÑ –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∞—è –∫–∞–ª–∏–±—Ä–æ–≤–∫–∞ ML –º–æ–¥–µ–ª–∏")
            self.train_ml_model()

    def get_ml_stats(self) -> Dict[str, Any]:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ ML –º–æ–¥–µ–ª–∏"""
        return {
            'model_trained': self.ml_model is not None,
            'training_examples': len(self.training_data),
            'prediction_history': len(self.prediction_history),
            'accuracy_stats': self.accuracy_stats.copy(),
            'feature_weights': self.feature_weights.copy(),
            'model_weights': self.ml_model.copy() if self.ml_model else None
        }

    def adaptive_confidence_calculation(self, result: Any, analysis: QueryAnalysis,
                                      user_feedback: Optional[float] = None) -> float:
        """
        –ê–¥–∞–ø—Ç–∏–≤–Ω—ã–π —Ä–∞—Å—á–µ—Ç —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏ —Å —É—á–µ—Ç–æ–º –æ–±—Ä–∞—Ç–Ω–æ–π —Å–≤—è–∑–∏.

        Args:
            result: –†–µ–∑—É–ª—å—Ç–∞—Ç –∑–∞–ø—Ä–æ—Å–∞
            analysis: –ê–Ω–∞–ª–∏–∑ –∑–∞–ø—Ä–æ—Å–∞
            user_feedback: –û–±—Ä–∞—Ç–Ω–∞—è —Å–≤—è–∑—å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è (0.0-1.0)

        Returns:
            –ê–¥–∞–ø—Ç–∏—Ä–æ–≤–∞–Ω–Ω–∞—è —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å
        """
        # –ë–∞–∑–æ–≤—ã–π —Ä–∞—Å—á–µ—Ç
        base_confidence = self.calculate_with_ml(result, analysis)

        if user_feedback is not None:
            # –ö–∞–ª–∏–±—Ä–æ–≤–∫–∞ –Ω–∞ –æ—Å–Ω–æ–≤–µ –æ–±—Ä–∞—Ç–Ω–æ–π —Å–≤—è–∑–∏
            self.calibrate_with_feedback(base_confidence, user_feedback)

            # –î–æ–±–∞–≤–ª–µ–Ω–∏–µ –ø—Ä–∏–º–µ—Ä–∞ –¥–ª—è –æ–±—É—á–µ–Ω–∏—è
            self.add_training_example(result, analysis, user_feedback)

            # –í–æ–∑–≤—Ä–∞—â–∞–µ–º –∫–æ–º–±–∏–Ω–∞—Ü–∏—é –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –∏ –æ–±—Ä–∞—Ç–Ω–æ–π —Å–≤—è–∑–∏
            # –ß–µ–º –±–æ–ª—å—à–µ –¥–∞–Ω–Ω—ã—Ö, —Ç–µ–º –±–æ–ª—å—à–µ –≤–µ—Å –æ–±—Ä–∞—Ç–Ω–æ–π —Å–≤—è–∑–∏
            feedback_weight = min(0.3, len(self.training_data) / 100.0)
            adapted_confidence = base_confidence * (1 - feedback_weight) + user_feedback * feedback_weight

            return adapted_confidence

        return base_confidence
